{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used ## to comment out file generation and kaggle commit, delete them if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path of the processed data\n",
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "train_file_path = os.path.join(processed_data_path, 'train.csv')\n",
    "test_file_path = os.path.join(processed_data_path, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file_path, index_col='PassengerId')\n",
    "test_df = pd.read_csv(test_file_path, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 33 columns):\n",
      "Survived              891 non-null int64\n",
      "Age                   891 non-null float64\n",
      "Fare                  891 non-null float64\n",
      "FamilySize            891 non-null int64\n",
      "IsMother              891 non-null int64\n",
      "IsMale                891 non-null int64\n",
      "Deck_A                891 non-null int64\n",
      "Deck_B                891 non-null int64\n",
      "Deck_C                891 non-null int64\n",
      "Deck_D                891 non-null int64\n",
      "Deck_E                891 non-null int64\n",
      "Deck_F                891 non-null int64\n",
      "Deck_G                891 non-null int64\n",
      "Deck_Z                891 non-null int64\n",
      "Pclass_1              891 non-null int64\n",
      "Pclass_2              891 non-null int64\n",
      "Pclass_3              891 non-null int64\n",
      "Title_Lady            891 non-null int64\n",
      "Title_Master          891 non-null int64\n",
      "Title_Miss            891 non-null int64\n",
      "Title_Mr              891 non-null int64\n",
      "Title_Mrs             891 non-null int64\n",
      "Title_Officer         891 non-null int64\n",
      "Title_Sir             891 non-null int64\n",
      "Fare_Bin_very_low     891 non-null int64\n",
      "Fare_Bin_low          891 non-null int64\n",
      "Fare_Bin_high         891 non-null int64\n",
      "Fare_Bin_very_high    891 non-null int64\n",
      "Embarked_C            891 non-null int64\n",
      "Embarked_Q            891 non-null int64\n",
      "Embarked_S            891 non-null int64\n",
      "AgeState_Adult        891 non-null int64\n",
      "AgeState_Child        891 non-null int64\n",
      "dtypes: float64(2), int64(31)\n",
      "memory usage: 236.7 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 32 columns):\n",
      "Age                   418 non-null float64\n",
      "Fare                  418 non-null float64\n",
      "FamilySize            418 non-null int64\n",
      "IsMother              418 non-null int64\n",
      "IsMale                418 non-null int64\n",
      "Deck_A                418 non-null int64\n",
      "Deck_B                418 non-null int64\n",
      "Deck_C                418 non-null int64\n",
      "Deck_D                418 non-null int64\n",
      "Deck_E                418 non-null int64\n",
      "Deck_F                418 non-null int64\n",
      "Deck_G                418 non-null int64\n",
      "Deck_Z                418 non-null int64\n",
      "Pclass_1              418 non-null int64\n",
      "Pclass_2              418 non-null int64\n",
      "Pclass_3              418 non-null int64\n",
      "Title_Lady            418 non-null int64\n",
      "Title_Master          418 non-null int64\n",
      "Title_Miss            418 non-null int64\n",
      "Title_Mr              418 non-null int64\n",
      "Title_Mrs             418 non-null int64\n",
      "Title_Officer         418 non-null int64\n",
      "Title_Sir             418 non-null int64\n",
      "Fare_Bin_very_low     418 non-null int64\n",
      "Fare_Bin_low          418 non-null int64\n",
      "Fare_Bin_high         418 non-null int64\n",
      "Fare_Bin_very_high    418 non-null int64\n",
      "Embarked_C            418 non-null int64\n",
      "Embarked_Q            418 non-null int64\n",
      "Embarked_S            418 non-null int64\n",
      "AgeState_Adult        418 non-null int64\n",
      "AgeState_Child        418 non-null int64\n",
      "dtypes: float64(2), int64(30)\n",
      "memory usage: 107.8 KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X = train_df.loc[:,'Age':].as_matrix().astype('float')\n",
    "y = train_df['Survived'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 32) (891,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 32) (712,)\n",
      "(179, 32) (179,)\n"
     ]
    }
   ],
   "source": [
    "#error?  see Check Scikit-Learn version, is it even installed?\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from scikit-learn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean survival in train : 0.383\n",
      "mean survival in test : 0.385\n"
     ]
    }
   ],
   "source": [
    "# average survival in train and test\n",
    "print 'mean survival in train : {0:.3f}'.format(np.mean(y_train))\n",
    "print 'mean survival in test : {0:.3f}'.format(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Scikit-Learn Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.4'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure you have Scikit-Learn v0.19. Else update it and restart kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda update -y scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model_dummy = DummyClassifier(strategy='most_frequent', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='most_frequent')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model_dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for baseline model : 0.61\n"
     ]
    }
   ],
   "source": [
    "print 'score for baseline model : {0:.2f}'.format(model_dummy.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peformance metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for baseline model : 0.61\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print 'accuracy for baseline model : {0:.2f}'.format(accuracy_score(y_test, model_dummy.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for baseline model: \n",
      " [[110   0]\n",
      " [ 69   0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print 'confusion matrix for baseline model: \\n {0}'.format(confusion_matrix(y_test, model_dummy.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for baseline model : 0.00\n",
      "recall for baseline model : 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# precision and recall scores\n",
    "print 'precision for baseline model : {0:.2f}'.format(precision_score(y_test, model_dummy.predict(X_test)))\n",
    "print 'recall for baseline model : {0:.2f}'.format(recall_score(y_test, model_dummy.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Kaggle  Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to the matrix\n",
    "#test_X = test_df.as_matrix().astype('float')\n",
    "test_X = test_df.values.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = model_dummy.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived' : predictions} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "submission_file_path = os.path.join(submission_data_path, '01_dummy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_file(model, filename):\n",
    "    # converting to the matrix\n",
    "#    test_X = test_df.as_matrix().astype('float')\n",
    "    test_X = test_df.values.astype('float')\n",
    "    # make predictions\n",
    "    predictions = model.predict(test_X)\n",
    "    # submission dataframe\n",
    "    df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived' : predictions})\n",
    "    # submission file\n",
    "    submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    # write to the file\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "##get_submission_file(model_dummy, '01_dummy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model_lr_1 = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model_lr_1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 1 : 0.83\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print 'score for logistic regression - version 1 : {0:.2f}'.format(model_lr_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression - version 1 : 0.83\n",
      "confusion matrix for logistic regression - version 1: \n",
      " [[95 15]\n",
      " [15 54]]\n",
      "precision for logistic regression - version 1 : 0.78\n",
      "recall for logistic regression - version 1 : 0.78\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "# accuracy\n",
    "print 'accuracy for logistic regression - version 1 : {0:.2f}'.format(accuracy_score(y_test, model_lr_1.predict(X_test)))\n",
    "# confusion matrix\n",
    "print 'confusion matrix for logistic regression - version 1: \\n {0}'.format(confusion_matrix(y_test, model_lr_1.predict(X_test)))\n",
    "# precision \n",
    "print 'precision for logistic regression - version 1 : {0:.2f}'.format(precision_score(y_test, model_lr_1.predict(X_test)))\n",
    "# precision \n",
    "print 'recall for logistic regression - version 1 : {0:.2f}'.format(recall_score(y_test, model_lr_1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02840734,  0.00455631, -0.50017004,  0.61922842, -0.81414743,\n",
       "         0.12823264, -0.17253857, -0.3935549 ,  0.52215009,  1.09939126,\n",
       "         0.40346551, -0.18369315, -0.30021027,  0.96558545,  0.4828179 ,\n",
       "        -0.34516075,  0.2825859 ,  1.21850072,  0.56334181, -1.4461251 ,\n",
       "         1.07146231, -0.11345499, -0.47306806,  0.16297319,  0.24746356,\n",
       "         0.2799826 ,  0.41282325,  0.49202889,  0.46214498,  0.14906872,\n",
       "         0.37253568,  0.73070692]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model coefficients\n",
    "model_lr_1.coef_\n",
    "#todo - find out what these relate to, maybe loose the meaningless ones for simplicity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "##get_submission_file(model_lr_1, '02_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!/home/kevin/anaconda3/envs/py27/bin/kaggle competitions submit -c titanic -f /home/kevin/Projects/titanic/data/external/02_lr.csv -m \"Logistic Regression v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model \n",
    "model_lr = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'C' = Regularization parameter, too high = overfit.  \n",
    "penalty = L1 / L2 = another reg param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[0.9, 1.0, 1.1, 5.0, 10.0, 50.0, 100.0, 1000.0], 'penalty' : ['l1','l2']}\n",
    "clf = GridSearchCV(model_lr, param_grid=parameters, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.9, 1.0, 1.1, 5.0, 10.0, 50.0, 100.0, 1000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_\n",
    "#LR1 used C 1.0, penalty l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score : 0.83\n"
     ]
    }
   ],
   "source": [
    "print 'best score : {0:.2f}'.format(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 2 : 0.83\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print 'score for logistic regression - version 2 : {0:.2f}'.format(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for baseline model: \n",
      " [[110   0]\n",
      " [ 69   0]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print 'confusion matrix for baseline model: \\n {0}'.format(confusion_matrix(y_test, model_dummy.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for LR model: \n",
      " [[95 15]\n",
      " [15 54]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print 'confusion matrix for LR model: \\n {0}'.format(confusion_matrix(y_test, model_lr_1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for optimised LR model: \n",
      " [[94 16]\n",
      " [15 54]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print 'confusion matrix for optimised LR model: \\n {0}'.format(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "#looks 1 worse on test data but does slightly better on predict / submission to kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Third Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "##get_submission_file(clf, '03_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!/home/kevin/anaconda3/envs/py27/bin/kaggle competitions submit -c titanic -f /home/kevin/Projects/titanic/data/external/03_lr.csv -m \"Logistic Regression v2 - Tuned - l1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:,0].min(),X_train_scaled[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model after standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [1.0, 10.0, 50.0, 100.0, 1000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base model \n",
    "model_lr = LogisticRegression(random_state=0)\n",
    "parameters = {'C':[1.0, 10.0, 50.0, 100.0, 1000.0], 'penalty' : ['l1','l2']}\n",
    "clf = GridSearchCV(model_lr, param_grid=parameters, cv=3)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132022471910112"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 2 : 0.84\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print 'score for logistic regression - version 2 : {0:.2f}'.format(clf.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for standardised LR model: \n",
      " [[106   4]\n",
      " [ 48  21]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print 'confusion matrix for standardised LR model: \\n {0}'.format(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "#feature standardisation seems better (zero mean); normalisation (0 to 1, -1 to 1) has big 0s bias (not survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle library\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the file paths\n",
    "model_file_path = os.path.join(os.path.pardir,'models','lr_model.pkl')\n",
    "scaler_file_path = os.path.join(os.path.pardir,'models','lr_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the files to write \n",
    "model_file_pickle = open(model_file_path, 'wb')\n",
    "scaler_file_pickle = open(scaler_file_path, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist the model and scaler\n",
    "pickle.dump(clf, model_file_pickle)\n",
    "pickle.dump(scaler, scaler_file_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the file\n",
    "model_file_pickle.close()\n",
    "scaler_file_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the persisted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open files in read mode\n",
    "model_file_pickle = open(model_file_path, 'r')\n",
    "scaler_file_pickle = open(scaler_file_path, 'r')\n",
    "# load files\n",
    "clf_loaded = pickle.load(model_file_pickle)\n",
    "scaler_loaded = pickle.load(scaler_file_pickle)\n",
    "# close files\n",
    "model_file_pickle.close()\n",
    "scaler_file_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [1.0, 10.0, 50.0, 100.0, 1000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for persisted logistic regression : 0.84\n"
     ]
    }
   ],
   "source": [
    "# transform the test data using loaded scaler object\n",
    "X_test_scaled = scaler_loaded.transform(X_test)\n",
    "# calculate the score using loaded model object \n",
    "print 'score for persisted logistic regression : {0:.2f}'.format(clf_loaded.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for standardised LR model: \n",
      " [[106   4]\n",
      " [ 48  21]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print 'confusion matrix for standardised LR model: \\n {0}'.format(confusion_matrix(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_file_with_standardization(model,filename, scaler):\n",
    "    # converting to the matrix\n",
    "#    test_X = test_df.as_matrix().astype('float')\n",
    "    test_X = test_df.values.astype('float')\n",
    "    # standardization\n",
    "    test_X = scaler.transform(test_X)\n",
    "    # make predictions\n",
    "    predictions = model.predict(test_X)\n",
    "    # submission dataframe\n",
    "    df_submission = pd.DataFrame({'PassengerId': test_df.index, 'Survived' : predictions})\n",
    "    # submission file\n",
    "    submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    # write to the file\n",
    "    df_submission.to_csv(submission_file_path, index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file_with_standardization(clf, '04_lr.csv', scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature standardization (see above)\n",
    "scaler = StandardScaler()\n",
    "or\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_1 = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "model_rf_1.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for random forest - version 1 : 0.82\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print 'score for random forest - version 1 : {0:.2f}'.format(model_rf_1.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file_with_standardization(model_rf_1, '04_rf.csv', scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[99 11]\n",
      " [22 47]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print 'confusion matrix: \\n {0}'.format(confusion_matrix(y_test, model_rf_1.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[10, 100, 200, 150, 250], \n",
    "              'min_samples_leaf':[1, 5,10,50, 3, 7],\n",
    "              'max_features' : ('auto','sqrt','log2'),\n",
    "             }\n",
    "rf = RandomForestClassifier(random_state=0, oob_score=True)\n",
    "clf = GridSearchCV(rf, parameters, cv=5)\n",
    "#clf = GridSearchCV(model_lr, param_grid=parameters, cv=3)\n",
    "\n",
    "#first pass: clf.best_params_ {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 200}.  0.83\n",
    "#second pass: {'max_features': 'auto', 'min_samples_leaf': 7, 'n_estimators': 100}  0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=True, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 100, 200, 150, 250], 'max_features': ('auto', 'sqrt', 'log2'), 'min_samples_leaf': [1, 5, 10, 50, 3, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=7, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=True, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'min_samples_leaf': 7, 'n_estimators': 100}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score for random forest : 0.83\n"
     ]
    }
   ],
   "source": [
    "# best score\n",
    "print 'best score for random forest : {0:.2f}'.format(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      " [[100  10]\n",
      " [ 20  49]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print 'confusion matrix: \\n {0}'.format(confusion_matrix(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file(clf, '05_rf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Metrics , Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268156424581006"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8158761528326746"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Final Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_df.values.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 2)\n"
     ]
    }
   ],
   "source": [
    "print predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89406578 0.10593422]\n",
      " [0.43265986 0.56734014]\n",
      " [0.82768001 0.17231999]\n",
      " [0.91318311 0.08681689]\n",
      " [0.31978926 0.68021074]\n",
      " [0.85868924 0.14131076]\n",
      " [0.33284987 0.66715013]\n",
      " [0.88942798 0.11057202]\n",
      " [0.18843    0.81157   ]\n",
      " [0.95126285 0.04873715]\n",
      " [0.91954613 0.08045387]\n",
      " [0.78071379 0.21928621]\n",
      " [0.07431248 0.92568752]\n",
      " [0.92021733 0.07978267]\n",
      " [0.03974827 0.96025173]\n",
      " [0.1287065  0.8712935 ]\n",
      " [0.754725   0.245275  ]\n",
      " [0.86304049 0.13695951]\n",
      " [0.46211798 0.53788202]\n",
      " [0.26534032 0.73465968]\n",
      " [0.75046131 0.24953869]\n",
      " [0.40357959 0.59642041]\n",
      " [0.09745879 0.90254121]\n",
      " [0.63230281 0.36769719]\n",
      " [0.08845008 0.91154992]\n",
      " [0.96118853 0.03881147]\n",
      " [0.07722602 0.92277398]\n",
      " [0.8659162  0.1340838 ]\n",
      " [0.68421636 0.31578364]\n",
      " [0.9333981  0.0666019 ]\n",
      " [0.90313587 0.09686413]\n",
      " [0.88002109 0.11997891]\n",
      " [0.47552562 0.52447438]\n",
      " [0.48276234 0.51723766]\n",
      " [0.67999878 0.32000122]\n",
      " [0.85813181 0.14186819]\n",
      " [0.38159203 0.61840797]\n",
      " [0.37755104 0.62244896]\n",
      " [0.91046444 0.08953556]\n",
      " [0.9245609  0.0754391 ]\n",
      " [0.91108525 0.08891475]\n",
      " [0.56134785 0.43865215]\n",
      " [0.93293236 0.06706764]\n",
      " [0.1397597  0.8602403 ]\n",
      " [0.07014142 0.92985858]\n",
      " [0.91063094 0.08936906]\n",
      " [0.59250723 0.40749277]\n",
      " [0.88524433 0.11475567]\n",
      " [0.04376272 0.95623728]\n",
      " [0.42756166 0.57243834]\n",
      " [0.7536235  0.2463765 ]\n",
      " [0.76061338 0.23938662]\n",
      " [0.37486532 0.62513468]\n",
      " [0.30176393 0.69823607]\n",
      " [0.76639499 0.23360501]\n",
      " [0.59482053 0.40517947]\n",
      " [0.92651738 0.07348262]\n",
      " [0.83696643 0.16303357]\n",
      " [0.94602365 0.05397635]\n",
      " [0.0594895  0.9405105 ]\n",
      " [0.87041143 0.12958857]\n",
      " [0.81255743 0.18744257]\n",
      " [0.905199   0.094801  ]\n",
      " [0.30441427 0.69558573]\n",
      " [0.10519989 0.89480011]\n",
      " [0.18133494 0.81866506]\n",
      " [0.29069246 0.70930754]\n",
      " [0.77005162 0.22994838]\n",
      " [0.64916263 0.35083737]\n",
      " [0.25356787 0.74643213]\n",
      " [0.31138162 0.68861838]\n",
      " [0.90931333 0.09068667]\n",
      " [0.4090046  0.5909954 ]\n",
      " [0.44313668 0.55686332]\n",
      " [0.0856571  0.9143429 ]\n",
      " [0.58568081 0.41431919]\n",
      " [0.91580434 0.08419566]\n",
      " [0.21810064 0.78189936]\n",
      " [0.80762229 0.19237771]\n",
      " [0.31138162 0.68861838]\n",
      " [0.38165294 0.61834706]\n",
      " [0.8336531  0.1663469 ]\n",
      " [0.78900275 0.21099725]\n",
      " [0.91954613 0.08045387]\n",
      " [0.73651177 0.26348823]\n",
      " [0.89678166 0.10321834]\n",
      " [0.3219681  0.6780319 ]\n",
      " [0.36626941 0.63373059]\n",
      " [0.24774508 0.75225492]\n",
      " [0.25833268 0.74166732]\n",
      " [0.32335095 0.67664905]\n",
      " [0.91955773 0.08044227]\n",
      " [0.10092908 0.89907092]\n",
      " [0.91580434 0.08419566]\n",
      " [0.61320402 0.38679598]\n",
      " [0.91457867 0.08542133]\n",
      " [0.21292322 0.78707678]\n",
      " [0.91581685 0.08418315]\n",
      " [0.38557891 0.61442109]\n",
      " [0.92071618 0.07928382]\n",
      " [0.09258951 0.90741049]\n",
      " [0.8648508  0.1351492 ]\n",
      " [0.88524433 0.11475567]\n",
      " [0.91585058 0.08414942]\n",
      " [0.20081369 0.79918631]\n",
      " [0.93021691 0.06978309]\n",
      " [0.87124924 0.12875076]\n",
      " [0.88524433 0.11475567]\n",
      " [0.91573802 0.08426198]\n",
      " [0.6250905  0.3749095 ]\n",
      " [0.79981421 0.20018579]\n",
      " [0.30439937 0.69560063]\n",
      " [0.06999791 0.93000209]\n",
      " [0.29254249 0.70745751]\n",
      " [0.15373041 0.84626959]\n",
      " [0.87888943 0.12111057]\n",
      " [0.87790246 0.12209754]\n",
      " [0.33073235 0.66926765]\n",
      " [0.6411272  0.3588728 ]\n",
      " [0.20375086 0.79624914]\n",
      " [0.15250297 0.84749703]\n",
      " [0.90821652 0.09178348]\n",
      " [0.08193576 0.91806424]\n",
      " [0.91838996 0.08161004]\n",
      " [0.88524433 0.11475567]\n",
      " [0.39585249 0.60414751]\n",
      " [0.91066435 0.08933565]\n",
      " [0.46024684 0.53975316]\n",
      " [0.83630783 0.16369217]\n",
      " [0.90927679 0.09072321]\n",
      " [0.91951335 0.08048665]\n",
      " [0.46900837 0.53099163]\n",
      " [0.54423322 0.45576678]\n",
      " [0.90218196 0.09781804]\n",
      " [0.93494781 0.06505219]\n",
      " [0.91328548 0.08671452]\n",
      " [0.87333591 0.12666409]\n",
      " [0.79724689 0.20275311]\n",
      " [0.38546116 0.61453884]\n",
      " [0.98835773 0.01164227]\n",
      " [0.70273192 0.29726808]\n",
      " [0.12818892 0.87181108]\n",
      " [0.80208291 0.19791709]\n",
      " [0.83528417 0.16471583]\n",
      " [0.76917499 0.23082501]\n",
      " [0.9674526  0.0325474 ]\n",
      " [0.38599544 0.61400456]\n",
      " [0.90654046 0.09345954]\n",
      " [0.72926934 0.27073066]\n",
      " [0.79769385 0.20230615]\n",
      " [0.05151003 0.94848997]\n",
      " [0.87769944 0.12230056]\n",
      " [0.94795235 0.05204765]\n",
      " [0.3715669  0.6284331 ]\n",
      " [0.73421192 0.26578808]\n",
      " [0.91331675 0.08668325]\n",
      " [0.11773994 0.88226006]\n",
      " [0.39727297 0.60272703]\n",
      " [0.61286565 0.38713435]\n",
      " [0.33376338 0.66623662]\n",
      " [0.30441199 0.69558801]\n",
      " [0.3855223  0.6144777 ]\n",
      " [0.19998679 0.80001321]\n",
      " [0.9196321  0.0803679 ]\n",
      " [0.69684604 0.30315396]\n",
      " [0.38617907 0.61382093]\n",
      " [0.614353   0.385647  ]\n",
      " [0.96612646 0.03387354]\n",
      " [0.06725076 0.93274924]\n",
      " [0.3813126  0.6186874 ]\n",
      " [0.91957933 0.08042067]\n",
      " [0.87423828 0.12576172]\n",
      " [0.92620955 0.07379045]\n",
      " [0.87779227 0.12220773]\n",
      " [0.98540744 0.01459256]\n",
      " [0.22192067 0.77807933]\n",
      " [0.20874121 0.79125879]\n",
      " [0.7594219  0.2405781 ]\n",
      " [0.13867992 0.86132008]\n",
      " [0.03171444 0.96828556]\n",
      " [0.80762229 0.19237771]\n",
      " [0.41550163 0.58449837]\n",
      " [0.04621773 0.95378227]\n",
      " [0.88524433 0.11475567]\n",
      " [0.04089197 0.95910803]\n",
      " [0.86210734 0.13789266]\n",
      " [0.27082833 0.72917167]\n",
      " [0.91317624 0.08682376]\n",
      " [0.89182459 0.10817541]\n",
      " [0.83177784 0.16822216]\n",
      " [0.87768949 0.12231051]\n",
      " [0.72941025 0.27058975]\n",
      " [0.51844383 0.48155617]\n",
      " [0.82483475 0.17516525]\n",
      " [0.26403472 0.73596528]\n",
      " [0.92426152 0.07573848]\n",
      " [0.02484825 0.97515175]\n",
      " [0.37787889 0.62212111]\n",
      " [0.78973457 0.21026543]\n",
      " [0.31709482 0.68290518]\n",
      " [0.34360398 0.65639602]\n",
      " [0.41401984 0.58598016]\n",
      " [0.4285089  0.5714911 ]\n",
      " [0.21485909 0.78514091]\n",
      " [0.79511786 0.20488214]\n",
      " [0.62868837 0.37131163]\n",
      " [0.35122537 0.64877463]\n",
      " [0.7924391  0.2075609 ]\n",
      " [0.07080624 0.92919376]\n",
      " [0.91456853 0.08543147]\n",
      " [0.93434822 0.06565178]\n",
      " [0.91962731 0.08037269]\n",
      " [0.72915972 0.27084028]\n",
      " [0.29823616 0.70176384]\n",
      " [0.7896278  0.2103722 ]\n",
      " [0.69914102 0.30085898]\n",
      " [0.30437189 0.69562811]\n",
      " [0.84700315 0.15299685]\n",
      " [0.08402853 0.91597147]\n",
      " [0.91580434 0.08419566]\n",
      " [0.17686038 0.82313962]\n",
      " [0.90514472 0.09485528]\n",
      " [0.06415256 0.93584744]\n",
      " [0.90932404 0.09067596]\n",
      " [0.08828251 0.91171749]\n",
      " [0.31589624 0.68410376]\n",
      " [0.91198678 0.08801322]\n",
      " [0.3044074  0.6955926 ]\n",
      " [0.94290346 0.05709654]\n",
      " [0.82241876 0.17758124]\n",
      " [0.72157781 0.27842219]\n",
      " [0.1306866  0.8693134 ]\n",
      " [0.92798148 0.07201852]\n",
      " [0.8852273  0.1147727 ]\n",
      " [0.70754351 0.29245649]\n",
      " [0.90795931 0.09204069]\n",
      " [0.61857394 0.38142606]\n",
      " [0.86109465 0.13890535]\n",
      " [0.26528834 0.73471166]\n",
      " [0.09391307 0.90608693]\n",
      " [0.09092308 0.90907692]\n",
      " [0.24512375 0.75487625]\n",
      " [0.431193   0.568807  ]\n",
      " [0.91954693 0.08045307]\n",
      " [0.54697365 0.45302635]\n",
      " [0.6463061  0.3536939 ]\n",
      " [0.15186226 0.84813774]\n",
      " [0.90770211 0.09229789]\n",
      " [0.20375086 0.79624914]\n",
      " [0.27056309 0.72943691]\n",
      " [0.23775606 0.76224394]\n",
      " [0.90374446 0.09625554]\n",
      " [0.64613725 0.35386275]\n",
      " [0.90914019 0.09085981]\n",
      " [0.9199784  0.0800216 ]\n",
      " [0.91957933 0.08042067]\n",
      " [0.88524433 0.11475567]\n",
      " [0.9145339  0.0854661 ]\n",
      " [0.18238373 0.81761627]\n",
      " [0.90932626 0.09067374]\n",
      " [0.95188127 0.04811873]\n",
      " [0.90931779 0.09068221]\n",
      " [0.20140449 0.79859551]\n",
      " [0.33870891 0.66129109]\n",
      " [0.72503992 0.27496008]\n",
      " [0.91954613 0.08045387]\n",
      " [0.69766343 0.30233657]\n",
      " [0.91957933 0.08042067]\n",
      " [0.38159203 0.61840797]\n",
      " [0.86462762 0.13537238]\n",
      " [0.67784939 0.32215061]\n",
      " [0.88524433 0.11475567]\n",
      " [0.06499857 0.93500143]\n",
      " [0.40172506 0.59827494]\n",
      " [0.87779286 0.12220714]\n",
      " [0.26633883 0.73366117]\n",
      " [0.80299973 0.19700027]\n",
      " [0.88784523 0.11215477]\n",
      " [0.87121684 0.12878316]\n",
      " [0.78700428 0.21299572]\n",
      " [0.38527287 0.61472713]\n",
      " [0.41588533 0.58411467]\n",
      " [0.3044074  0.6955926 ]\n",
      " [0.31670268 0.68329732]\n",
      " [0.3954186  0.6045814 ]\n",
      " [0.92768004 0.07231996]\n",
      " [0.91960812 0.08039188]\n",
      " [0.67831258 0.32168742]\n",
      " [0.77494699 0.22505301]\n",
      " [0.91580434 0.08419566]\n",
      " [0.71456789 0.28543211]\n",
      " [0.33304565 0.66695435]\n",
      " [0.87779227 0.12220773]\n",
      " [0.56095924 0.43904076]\n",
      " [0.92409482 0.07590518]\n",
      " [0.9158385  0.0841615 ]\n",
      " [0.15402926 0.84597074]\n",
      " [0.9333981  0.0666019 ]\n",
      " [0.71634049 0.28365951]\n",
      " [0.91955013 0.08044987]\n",
      " [0.92311527 0.07688473]\n",
      " [0.60932448 0.39067552]\n",
      " [0.89326182 0.10673818]\n",
      " [0.90921119 0.09078881]\n",
      " [0.3044074  0.6955926 ]\n",
      " [0.1491724  0.8508276 ]\n",
      " [0.83137223 0.16862777]\n",
      " [0.35855818 0.64144182]\n",
      " [0.81573934 0.18426066]\n",
      " [0.4104032  0.5895968 ]\n",
      " [0.90077395 0.09922605]\n",
      " [0.86496335 0.13503665]\n",
      " [0.91957693 0.08042307]\n",
      " [0.35871907 0.64128093]\n",
      " [0.08023827 0.91976173]\n",
      " [0.22384157 0.77615843]\n",
      " [0.67640359 0.32359641]\n",
      " [0.77865884 0.22134116]\n",
      " [0.91709541 0.08290459]\n",
      " [0.87652221 0.12347779]\n",
      " [0.91585058 0.08414942]\n",
      " [0.76332576 0.23667424]\n",
      " [0.65338374 0.34661626]\n",
      " [0.7419976  0.2580024 ]\n",
      " [0.1305078  0.8694922 ]\n",
      " [0.91206444 0.08793556]\n",
      " [0.14309242 0.85690758]\n",
      " [0.66353842 0.33646158]\n",
      " [0.86863085 0.13136915]\n",
      " [0.78369871 0.21630129]\n",
      " [0.24217991 0.75782009]\n",
      " [0.56860264 0.43139736]\n",
      " [0.87779286 0.12220714]\n",
      " [0.26208241 0.73791759]\n",
      " [0.9170913  0.0829087 ]\n",
      " [0.74415222 0.25584778]\n",
      " [0.81265625 0.18734375]\n",
      " [0.93297532 0.06702468]\n",
      " [0.81921091 0.18078909]\n",
      " [0.23289639 0.76710361]\n",
      " [0.77582556 0.22417444]\n",
      " [0.92313331 0.07686669]\n",
      " [0.99316589 0.00683411]\n",
      " [0.03767172 0.96232828]\n",
      " [0.487771   0.512229  ]\n",
      " [0.29601486 0.70398514]\n",
      " [0.79724689 0.20275311]\n",
      " [0.24361675 0.75638325]\n",
      " [0.79179795 0.20820205]\n",
      " [0.25430734 0.74569266]\n",
      " [0.03451202 0.96548798]\n",
      " [0.79511786 0.20488214]\n",
      " [0.79281005 0.20718995]\n",
      " [0.93132727 0.06867273]\n",
      " [0.44867714 0.55132286]\n",
      " [0.49233905 0.50766095]\n",
      " [0.21398386 0.78601614]\n",
      " [0.91954773 0.08045227]\n",
      " [0.88524433 0.11475567]\n",
      " [0.40827014 0.59172986]\n",
      " [0.87943425 0.12056575]\n",
      " [0.1192849  0.8807151 ]\n",
      " [0.17181936 0.82818064]\n",
      " [0.91318311 0.08681689]\n",
      " [0.01794064 0.98205936]\n",
      " [0.82604129 0.17395871]\n",
      " [0.91686378 0.08313622]\n",
      " [0.41540936 0.58459064]\n",
      " [0.07031218 0.92968782]\n",
      " [0.72147332 0.27852668]\n",
      " [0.82321618 0.17678382]\n",
      " [0.02277669 0.97722331]\n",
      " [0.70683239 0.29316761]\n",
      " [0.84073919 0.15926081]\n",
      " [0.10355305 0.89644695]\n",
      " [0.08867655 0.91132345]\n",
      " [0.50359814 0.49640186]\n",
      " [0.78402854 0.21597146]\n",
      " [0.80048392 0.19951608]\n",
      " [0.70789481 0.29210519]\n",
      " [0.88524433 0.11475567]\n",
      " [0.88014426 0.11985574]\n",
      " [0.36890264 0.63109736]\n",
      " [0.36543631 0.63456369]\n",
      " [0.8050924  0.1949076 ]\n",
      " [0.36429745 0.63570255]\n",
      " [0.91329362 0.08670638]\n",
      " [0.86720609 0.13279391]\n",
      " [0.87125955 0.12874045]\n",
      " [0.61615365 0.38384635]\n",
      " [0.61445835 0.38554165]\n",
      " [0.06084392 0.93915608]\n",
      " [0.52270761 0.47729239]\n",
      " [0.84762282 0.15237718]\n",
      " [0.97348076 0.02651924]\n",
      " [0.09690675 0.90309325]\n",
      " [0.87673674 0.12326326]\n",
      " [0.06959321 0.93040679]\n",
      " [0.91066655 0.08933345]\n",
      " [0.88852965 0.11147035]\n",
      " [0.12744075 0.87255925]\n",
      " [0.88520565 0.11479435]\n",
      " [0.1003031  0.8996969 ]\n",
      " [0.59299124 0.40700876]\n",
      " [0.56410458 0.43589542]\n",
      " [0.51504794 0.48495206]\n",
      " [0.82811385 0.17188615]\n",
      " [0.75593172 0.24406828]\n",
      " [0.30441542 0.69558458]\n",
      " [0.34561065 0.65438935]\n",
      " [0.3044074  0.6955926 ]\n",
      " [0.08679494 0.91320506]\n",
      " [0.41704522 0.58295478]\n",
      " [0.91580434 0.08419566]\n",
      " [0.12591438 0.87408562]\n",
      " [0.93037721 0.06962279]\n",
      " [0.91580434 0.08419566]\n",
      " [0.37180093 0.62819907]]\n"
     ]
    }
   ],
   "source": [
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
